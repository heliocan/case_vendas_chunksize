{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393232c1f33ed7a9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Funcoes opcionais para estudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04355bacb82c0ac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_resource_usage():\n",
    "    \"\"\"\n",
    "    Mede o uso de CPU e memória do processo atual.\n",
    "\n",
    "    Esta função usa a biblioteca `psutil` para medir o uso de CPU e memória\n",
    "    do processo Python em execução. O uso de CPU é medido ao longo de um\n",
    "    intervalo de 1 segundo, e o uso de memória é convertido para megabytes (MB).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Uma tupla contendo:\n",
    "            - cpu_usage (float): O uso de CPU em porcentagem.\n",
    "            - memory_usage (float): O uso de memória em megabytes (MB).\n",
    "    \"\"\"\n",
    "    process = psutil.Process()\n",
    "    cpu_usage = process.cpu_percent(interval=1)\n",
    "    memory_info = process.memory_info()\n",
    "    memory_usage = memory_info.rss / (1024 ** 2)  # Convertendo para MB\n",
    "    return cpu_usage, memory_usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93224490ade65a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Funcoes da solucao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67118daf1cf76423",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \"\"\"\n",
    "    Renomeia as colunas de um DataFrame, convertendo todas para minúsculas e substituindo espaços por underscores.\n",
    "\n",
    "    Esta função toma um DataFrame como entrada e aplica duas transformações nas suas colunas:\n",
    "    1. Converte todos os caracteres das colunas para minúsculas.\n",
    "    2. Substitui espaços em branco nas colunas por underscores (_).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame cujas colunas serão renomeadas.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: O DataFrame com as colunas renomeadas.\n",
    "    \"\"\"\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4c421a51dd751",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def read_csv_to_df(filename):\n",
    "    \"\"\"\n",
    "    Lê um arquivo CSV em chunks, infere tipos de dados, filtra colunas necessárias e otimiza o uso de memória.\n",
    "    Durante o carregamento dos chunks, calcula os seguintes resultados:\n",
    "    1. Produto mais vendido em termos de quantidade e canal.\n",
    "    2. País e região com o maior volume de vendas (em valor).\n",
    "    3. Média de vendas mensais por produto.\n",
    "\n",
    "    Args:\n",
    "        filename (str): O caminho para o arquivo CSV.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário com os resultados das três perguntas em formato JSON.\n",
    "    \"\"\"\n",
    "    # Colunas necessárias para as perguntas do desafio\n",
    "    colunas_necessarias = ['Item Type', 'Units Sold', 'Sales Channel', 'Country', 'Region', 'Total Revenue', 'Order Date']\n",
    "    \n",
    "    # Carregar uma amostra para inferir tipos de dados\n",
    "    flat_file = pd.read_csv(filename, low_memory=False, nrows=1000)\n",
    "    types = flat_file.dtypes\n",
    "    types = types.apply(str)\n",
    "\n",
    "    dict_types = types.to_dict()\n",
    "\n",
    "    # Inicializando estruturas para armazenar resultados intermediários\n",
    "    vendas_por_produto_canal = defaultdict(int)\n",
    "    vendas_por_pais_regiao = defaultdict(float)\n",
    "    vendas_mensais_produto = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for chunk in pd.read_csv(filename, low_memory=False, dtype=dict_types, chunksize=1000000, usecols=colunas_necessarias):\n",
    "        # Renomeando colunas\n",
    "        chunk = rename_columns(chunk)\n",
    "        \n",
    "        # Convertendo 'order_date' para datetime\n",
    "        chunk['order_date'] = pd.to_datetime(chunk['order_date'])\n",
    "        \n",
    "        # Otimizar inteiros\n",
    "        ints = chunk.select_dtypes(include=['int64', 'int32', 'int16']).columns\n",
    "        chunk[ints] = chunk[ints].apply(pd.to_numeric, downcast='integer')\n",
    "\n",
    "        # Otimizar floats\n",
    "        floats = chunk.select_dtypes(include=['float']).columns\n",
    "        chunk[floats] = chunk[floats].apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "        # Otimizar objetos\n",
    "        objects = chunk.select_dtypes('object').columns\n",
    "        chunk[objects] = chunk[objects].apply(lambda x: x.astype('category'))\n",
    "\n",
    "        # Atualizando vendas por produto e canal\n",
    "        grouped_produto_canal = chunk.groupby(['sales_channel', 'item_type'], observed=True)['units_sold'].sum()\n",
    "        for (sales_channel, item_type), units_sold in grouped_produto_canal.items():\n",
    "            vendas_por_produto_canal[(sales_channel, item_type)] += units_sold\n",
    "\n",
    "        # Atualizando vendas por país e região\n",
    "        grouped_pais_regiao = chunk.groupby(['region', 'country'], observed=True)['total_revenue'].sum()\n",
    "        for (region, country), total_revenue in grouped_pais_regiao.items():\n",
    "            vendas_por_pais_regiao[(region, country)] += total_revenue\n",
    "\n",
    "        # Atualizando vendas mensais por produto\n",
    "        chunk['year_month'] = chunk['order_date'].dt.to_period('M')\n",
    "        grouped_mensal_produto = chunk.groupby(['year_month', 'item_type'], observed=True)['units_sold'].sum()\n",
    "        for (year_month, item_type), units_sold in grouped_mensal_produto.items():\n",
    "            vendas_mensais_produto[year_month][item_type] += units_sold\n",
    "\n",
    "    # Convertendo resultados para DataFrames\n",
    "    df_vendas_por_produto_canal = pd.DataFrame.from_dict(vendas_por_produto_canal, orient='index', columns=['units_sold']).reset_index()\n",
    "    df_vendas_por_produto_canal[['sales_channel', 'item_type']] = pd.DataFrame(df_vendas_por_produto_canal['index'].tolist(), index=df_vendas_por_produto_canal.index)\n",
    "    df_vendas_por_produto_canal = df_vendas_por_produto_canal.drop(columns=['index'])\n",
    "    idx = df_vendas_por_produto_canal.groupby('sales_channel', observed=True)['units_sold'].idxmax()\n",
    "    produto_mais_vendido_por_canal = df_vendas_por_produto_canal.loc[idx].reset_index(drop=True)\n",
    "\n",
    "    df_vendas_por_pais_regiao = pd.DataFrame.from_dict(vendas_por_pais_regiao, orient='index', columns=['total_revenue']).reset_index()\n",
    "    df_vendas_por_pais_regiao[['region', 'country']] = pd.DataFrame(df_vendas_por_pais_regiao['index'].tolist(), index=df_vendas_por_pais_regiao.index)\n",
    "    df_vendas_por_pais_regiao = df_vendas_por_pais_regiao.drop(columns=['index'])\n",
    "    idx = df_vendas_por_pais_regiao['total_revenue'].idxmax()\n",
    "    maior_volume_vendas_pais_regiao = df_vendas_por_pais_regiao.loc[idx].reset_index(drop=True)\n",
    "\n",
    "    df_vendas_mensais_produto = pd.DataFrame([(key, item_type, sum(units_sold.values())) for key, units_sold in vendas_mensais_produto.items() for item_type in units_sold.keys()], columns=['year_month', 'item_type', 'units_sold'])\n",
    "    media_vendas_mensais_por_produto = df_vendas_mensais_produto.groupby('item_type')['units_sold'].mean().reset_index()\n",
    "    media_vendas_mensais_por_produto.columns = ['item_type', 'average_monthly_units_sold']\n",
    "\n",
    "    # Preparando os resultados para JSON\n",
    "    resultados = {\n",
    "        \"produto_mais_vendido_por_canal\": produto_mais_vendido_por_canal.to_dict(orient='records'),\n",
    "        \"maior_volume_vendas_pais_regiao\": maior_volume_vendas_pais_regiao.to_dict(),\n",
    "        \"media_vendas_mensais_por_produto\": media_vendas_mensais_por_produto.to_dict(orient='records')\n",
    "    }\n",
    "    \n",
    "    chunk.info(memory_usage='deep')\n",
    "\n",
    "    return json.dumps(resultados, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9e5181949741c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def read_horse(filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # Carregar uma amostra para inferir tipos de dados\n",
    "    data = pd.read_csv(filename)\n",
    "    data.info(memory_usage='deep')\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8f2c43f30c2d9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    file_path = 'vendas.csv'\n",
    "    \n",
    "    # metricas de uso\n",
    "    cpu_before, mem_before = get_resource_usage()\n",
    "    print(f\"Início = CPU: {cpu_before}% | Memória RAM: {mem_before:.2f} MB\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    resultados_json = read_csv_to_df(file_path)\n",
    "    print(resultados_json)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "\n",
    "    cpu_after, mem_after = get_resource_usage()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"{elapsed_time:.2f} segundos. CPU: {cpu_after}% | Memória RAM: {mem_after:.2f} MB | Uso Memória RAM:\"\n",
    "          f\" {mem_after - mem_before:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159c9cc8d57d9f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Chamada sem otimizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6656c12ab10bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def main_hourse():\n",
    "    \n",
    "    file_path = 'vendas.csv'\n",
    "    \n",
    "    # metricas de uso\n",
    "    cpu_before, mem_before = get_resource_usage()\n",
    "    print(f\"Início = CPU: {cpu_before}% | Memória RAM: {mem_before:.2f} MB\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    df = read_horse(file_path)\n",
    "    end_time = time.time()\n",
    "\n",
    "    cpu_after, mem_after = get_resource_usage()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"{elapsed_time:.2f} segundos. CPU: {cpu_after}% | Memória RAM: {mem_after:.2f} MB | Uso Memória RAM:\"\n",
    "          f\" {mem_after - mem_before:.2f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79933ee96d3e022d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# main_hourse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc453abbf965e6d3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Chamada com otimizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380629d7b3a6db4a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126df1ddb86d2b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
